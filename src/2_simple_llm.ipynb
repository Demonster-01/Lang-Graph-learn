{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "0a8fe1fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph,START,END\n",
    "from langchain_openai import ChatOpenAI\n",
    "from typing import TypedDict\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "# os.environ[\"LANGSMITH_NOTEBOOK_RENDER\"] = \"false\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "c677edde",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()  \n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "01196c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LLMState(TypedDict):\n",
    "    question: str\n",
    "    answer: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "67d04d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def llm_QA(LLMState)->LLMState:\n",
    "#     llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n",
    "#     # extract question from state\n",
    "#     question=LLMState[\"question\"]\n",
    "#     # form a prompt\n",
    "#     prompt=f\"Answer the following question in a concise manner: {question}\"\n",
    "\n",
    "#     # ask the qurstion\n",
    "#     answer=llm.invoke(prompt).content\n",
    "#     state[\"answer\"]=answer\n",
    "#     return state\n",
    "\n",
    "    # return {\"question\":question, \"answer\":answer.content}\n",
    "\n",
    "\n",
    "def llm_QA(state: LLMState) -> LLMState:\n",
    "    llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n",
    "    \n",
    "    # extract question\n",
    "    question = state[\"question\"]\n",
    "    prompt = f\"Answer the following question in a concise manner: {question}\"\n",
    "\n",
    "    # ask the question\n",
    "    answer = llm.invoke(prompt).content\n",
    "\n",
    "    # update state\n",
    "    state[\"answer\"] = answer\n",
    "    return state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "bd4f90cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph=StateGraph(LLMState)\n",
    "\n",
    "graph.add_node(\"llm_QA\",llm_QA)\n",
    "\n",
    "graph.add_edge(START, \"llm_QA\")\n",
    "graph.add_edge(\"llm_QA\", END)\n",
    "\n",
    "app = graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "0f009712",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Communication is key in any relationship. Make sure to openly and honestly communicate with your partner to avoid misunderstandings and build trust.\n",
      "\n",
      "2. Remember to prioritize your partner and make time for them in your busy schedule. Showing love and appreciation regularly can help strengthen your relationship.\n"
     ]
    }
   ],
   "source": [
    " initial_state={'question':\"2 relationship advice\"}\n",
    "\n",
    " final_state = app.invoke(initial_state)\n",
    "\n",
    " print(final_state['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cba5d68",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lang-graph-learn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
