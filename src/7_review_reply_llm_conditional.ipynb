{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bfb06bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, END,START\n",
    "from langchain_openai import ChatOpenAI\n",
    "from typing import TypedDict,Literal\n",
    "from dotenv import load_dotenv\n",
    "from pydantic import BaseModel , Field\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3071a1b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "model=ChatOpenAI(model=\"gpt-4o-mini\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "67877a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentimentSchema(BaseModel):\n",
    "    sentiment:Literal[\"positive\",\"negative\"]= Field(description=\"sentiment of the review\")\n",
    "\n",
    "class diagnosisSchema(BaseModel):\n",
    "    issue_type:Literal[\"UX\",\"performance\",\"Bug\",\"Support\",\"other\"]=Field(description='the issue type mention in the review')\n",
    "    tone:Literal[\"angry\",\"calm\",\"frustrated\",\"other\"]=Field(description=\"the emotion and tone of the review\")\n",
    "    urgency:Literal[\"high\",\"medium\",\"low\"]=Field(description=\"the urgency of the issue like how urgent and critical the issue is\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "32a0d410",
   "metadata": {},
   "outputs": [],
   "source": [
    "structure_model=model.with_structured_output(SentimentSchema)\n",
    "diagnosis_model=model.with_structured_output(diagnosisSchema)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cdb9057e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReviewState(TypedDict):\n",
    "    review:str\n",
    "    sentiment:Literal[\"positive\",\"negative\"]\n",
    "    diagnosis:dict\n",
    "    response:str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "89aa0131",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt='what is the sentiment of the following review.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "795e78c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_sentiment(state:ReviewState):\n",
    "    prompt=f'For the following review find out the sentiment {state[\"review\"]}'\n",
    "    sentiment=structure_model.invoke(prompt).sentiment\n",
    "    return{\"sentiment\":sentiment}\n",
    "\n",
    "def check_sentiment(state:ReviewState)->Literal[\"positive_resonse\",\"run_diagnosis\"]:\n",
    "    if state[\"sentiment\"]== \"positive\":\n",
    "        return \"positive_response\"\n",
    "    else:\n",
    "        return \"run_diagnosis\"\n",
    "\n",
    "def positive_resonse(state:ReviewState):\n",
    "    prompt=f'write a short and sweet response to the following review {state[\"review\"]}'\n",
    "    response=model.invoke(prompt).content\n",
    "    return{\"response\":response}\n",
    "\n",
    "def run_diagnosis(state:ReviewState):\n",
    "    prompt=f'Diagnosis the following review : {state[\"review\"]} \\n return issue type , tone and urgency'\n",
    "    response = diagnosis_model.invoke(prompt)\n",
    "    return {\"diagnosis\":response.model_dump()}\n",
    "\n",
    "def negative_resonse(state:ReviewState):\n",
    "    diagnosis=state[\"diagnosis\"]\n",
    "    prompt=f'you are the support assistant. User had a {diagnosis[\"issue_type\"]} issue with {diagnosis[\"tone\"]} tone and {diagnosis[\"urgency\"]} urgency. \\n write a short and sweet response to the following review {state[\"review\"]}'\n",
    "    response=model.invoke(prompt).content\n",
    "    return{\"response\":response}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "679a6950",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph=StateGraph(ReviewState)\n",
    "graph.add_node(\"find_sentiment\",find_sentiment)\n",
    "graph.add_node(\"positive_resonse\",positive_resonse)\n",
    "graph.add_node(\"run_diagnosis\",run_diagnosis)\n",
    "graph.add_node(\"negative_resonse\",negative_resonse)\n",
    "\n",
    "graph.add_edge(START,\"find_sentiment\")\n",
    "graph.add_conditional_edges(\"find_sentiment\",check_sentiment)\n",
    "graph.add_edge(\"positive_resonse\", END)\n",
    "graph.add_edge(\"run_diagnosis\",\"negative_resonse\")\n",
    "graph.add_edge(\"negative_resonse\", END)\n",
    "workflow=graph.compile()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "03732fc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'review': 'the app is good but it crashes sometimes',\n",
       " 'sentiment': 'negative',\n",
       " 'diagnosis': {'issue_type': 'Bug', 'tone': 'calm', 'urgency': 'medium'},\n",
       " 'response': \"Thank you for your feedback! We're glad to hear you enjoy the app, but we’re sorry to hear about the crashes. Our team is working diligently to resolve this issue. Please make sure you’re using the latest version, and feel free to share any specific details that could help us improve. Your support means a lot to us!\"}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial_state={\"review\":\"the app is good but it crashes sometimes\"}\n",
    "workflow.invoke(initial_state)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c78e11",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lang-graph-learn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
